{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632ac52e-8a3b-47b7-9474-b535e2ede75f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'komt' already exists and is not an empty directory.\n",
      "Requirement already satisfied: bitsandbytes>=0.39.0 in /opt/conda/lib/python3.8/site-packages (from -r ./komt/lora/requirements_lora.txt (line 1)) (0.41.1)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.8/site-packages (from -r ./komt/lora/requirements_lora.txt (line 2)) (0.6.0.dev0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from -r ./komt/lora/requirements_lora.txt (line 3)) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from peft->-r ./komt/lora/requirements_lora.txt (line 2)) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from peft->-r ./komt/lora/requirements_lora.txt (line 2)) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from peft->-r ./komt/lora/requirements_lora.txt (line 2)) (5.7.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from peft->-r ./komt/lora/requirements_lora.txt (line 2)) (5.3.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from peft->-r ./komt/lora/requirements_lora.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (from peft->-r ./komt/lora/requirements_lora.txt (line 2)) (4.32.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from peft->-r ./komt/lora/requirements_lora.txt (line 2)) (4.65.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.8/site-packages (from peft->-r ./komt/lora/requirements_lora.txt (line 2)) (0.22.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.8/site-packages (from peft->-r ./komt/lora/requirements_lora.txt (line 2)) (0.3.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (46.4.0.post20200518)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (0.34.2)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (3.27.2)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (16.0.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.8/site-packages (from transformers->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (2023.8.8)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (0.13.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (2.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (2020.6.20)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=1.13.0->peft->-r ./komt/lora/requirements_lora.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/davidkim205/komt\n",
    "!pip install -r ./komt/lora/requirements_lora.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0e6a0-7762-4717-a01a-b78e858ef7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2139c7edc34dd3a8aa6455a896589d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "from transformers import TextStreamer, GenerationConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "class LocalStoppingCriteria(StoppingCriteria):\n",
    "\n",
    "    def __init__(self, tokenizer, stop_words = []):\n",
    "        super().__init__()\n",
    "\n",
    "        stops = [tokenizer(stop_word, return_tensors='pt', add_special_tokens = False)['input_ids'].squeeze() for stop_word in stop_words]\n",
    "        print('stop_words', stop_words)\n",
    "        print('stop_words_ids', stops)\n",
    "        self.stop_words = stop_words\n",
    "        self.stops = [stop.cuda() for stop in stops]\n",
    "        self.tokenizer = tokenizer\n",
    "    def _compare_token(self, input_ids):\n",
    "        for stop in self.stops:\n",
    "            if len(stop.size()) != 1:\n",
    "                continue\n",
    "            stop_len = len(stop)\n",
    "            if torch.all((stop == input_ids[0][-stop_len:])).item():\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "    def _compare_decode(self, input_ids):\n",
    "        input_str = self.tokenizer.decode(input_ids[0])\n",
    "        for stop_word in self.stop_words:\n",
    "            if input_str.endswith(stop_word):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\n",
    "        input_str = self.tokenizer.decode(input_ids[0])\n",
    "        for stop_word in self.stop_words:\n",
    "            if input_str.endswith(stop_word):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "#\n",
    "# config\n",
    "peft_model_name = 'davidkim205/komt-Llama-2-7b-chat-hf-lora'\n",
    "model_name = 'davidkim205/komt-Llama-2-7b-chat-hf'\n",
    "instruction_prefix = \"### instruction: \"\n",
    "input_prefix = \"### input: \"\n",
    "answer_prefix = \"### Response: \"\n",
    "endoftext = \"<|end|>\"\n",
    "stop_words = [endoftext, '<s>', '###']\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0.9,\n",
    "    top_p=0.7,\n",
    "    top_k=100,\n",
    "    max_new_tokens=2048,\n",
    "    early_stopping=True,\n",
    "    do_sample=True,\n",
    ")\n",
    "#\n",
    "# create model\n",
    "config = PeftConfig.from_pretrained(peft_model_name)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config,\n",
    "                                             device_map=\"auto\")\n",
    "model = PeftModel.from_pretrained(model, peft_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "stopping_criteria = StoppingCriteriaList([LocalStoppingCriteria(tokenizer=tokenizer, stop_words=stop_words)])\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "model.eval()\n",
    "\n",
    "#\n",
    "# generate\n",
    "prompt = f\"### instruction: 다음을 참고하여 600~700자로 글을 쓰시오. 창의력은 새로운 것을 생각해 내는 능력이다. 현대 사회는 개인에게 창의력을 더 맣이 요구하고 있다. 아래의 내용을 중심으로 '창의력의 필요성과 이를 기르기 위한 노력'에 대한 자신의 생각을 쓰라.- 창의력이 필요한 이유는 무엇인가?- 창의력을 발휘했을 때 얻을 수 있는 성과는 무엇인가?- 창의력을 기르기 위해서 어떠한 노력을 할 수 있는가?.\\n\\n### Response:\"\n",
    "gened = model.generate(\n",
    "    **tokenizer(\n",
    "        prompt,\n",
    "        return_tensors='pt',\n",
    "        return_token_type_ids=False\n",
    "    ).to('cuda'),\n",
    "    generation_config=generation_config,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    stopping_criteria=stopping_criteria,\n",
    "    streamer=streamer\n",
    ")\n",
    "output_text = tokenizer.decode(gened[0], skip_special_tokens=True)\n",
    "\n",
    "print('--------------------')\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee01a17-291b-4f3f-897e-61434a288e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
